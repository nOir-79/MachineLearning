{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25265cce-f5a5-41d9-af91-7d16c4bf6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2362f0a1-aa40-4a8c-a283-7196fbb3f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2'\n",
    "EASY_HAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2'\n",
    "HARD_HAM_URL = 'https://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2866ac-3023-448c-8840-f1cf833ce99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = 'datasets'\n",
    "TAR_DIR = os.path.join(DATASETS_DIR,'tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e87e71c-eb8b-48a3-8ceb-27c0bcbedb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.isdir(DATASETS_DIR):\n",
    "    shutil.rmtree(DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1645c980-4f56-4cbb-8490-b77a63a69091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "def download_dataset(url):\n",
    "    \"\"\"download and unzip data from a url into the specified path\"\"\"\n",
    "    \n",
    "    # create directory if it doesn't exist\n",
    "    if not os.path.isdir(TAR_DIR):\n",
    "        os.makedirs(TAR_DIR)\n",
    "    \n",
    "    filename = url.rsplit('/', 1)[-1]\n",
    "    tarpath = os.path.join(TAR_DIR, filename)\n",
    "    \n",
    "    # download the tar file if it doesn't exist\n",
    "    try:\n",
    "        tarfile.open(tarpath)\n",
    "    except:\n",
    "        urlretrieve(url, tarpath)\n",
    "    \n",
    "    with tarfile.open(tarpath) as tar:\n",
    "        dirname = os.path.join(DATASETS_DIR, tar.getnames()[0])\n",
    "        if os.path.isdir(dirname):\n",
    "            shutil.rmtree(dirname)\n",
    "        tar.extractall(path=DATASETS_DIR)\n",
    "        \n",
    "        cmds_path = os.path.join(dirname, 'cmds')\n",
    "        if os.path.isfile(cmds_path):\n",
    "            os.remove(cmds_path)\n",
    "    \n",
    "    return dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c213dd47-061f-47d9-a3e6-24f21c8e246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dir = download_dataset(SPAM_URL)\n",
    "easy_ham_dir = download_dataset(EASY_HAM_URL)\n",
    "hard_ham_dir = download_dataset(HARD_HAM_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad1397a-b8bc-4161-8421-dd9bfc063098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def load_dataset(dirpath):\n",
    "    \"\"\"load emails from the specified directory\"\"\"\n",
    "    \n",
    "    files = []\n",
    "    filepaths = glob.glob(dirpath + '/*')\n",
    "    for path in filepaths:\n",
    "        with open(path, 'rb') as f:\n",
    "            byte_content = f.read()\n",
    "            str_content = byte_content.decode('utf-8', errors='ignore')\n",
    "            files.append(str_content)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca14de60-8560-4259-a095-e15f1d0057c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = load_dataset(spam_dir)\n",
    "easy_ham = load_dataset(easy_ham_dir)\n",
    "hard_ham = load_dataset(hard_ham_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dae5ccc-966c-4864-a06b-ce34d8e51b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spam+easy_ham+hard_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e004bd8-6a5e-49a9-80f9-bb80d6cc8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.concatenate([np.ones(len(spam)),np.zeros(len(easy_ham)+len(hard_ham))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57d2907a-e4f2-4bcc-8f4b-b6880e818416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3046,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c76f20-6cb5-419f-bfe5-bc45337bff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c40e48b5-97d2-404a-90cb-ff7ce02c7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_body(email_string):\n",
    "    # Parse the email string into an EmailMessage object\n",
    "    msg = email.message_from_string(email_string, policy=policy.default)\n",
    "    \n",
    "    # Initialize an empty string to hold the email body\n",
    "    body = \"\"\n",
    "    \n",
    "    # Check if the email message is multipart\n",
    "    if msg.is_multipart():\n",
    "        # Iterate through the parts\n",
    "        for part in msg.iter_parts():\n",
    "            # If the part is text/plain or text/html, extract the content\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                charset = part.get_content_charset()\n",
    "                try:\n",
    "                    body += part.get_payload(decode=True).decode(charset, errors='ignore')\n",
    "                except (TypeError, UnicodeDecodeError):\n",
    "                    # Fallback to a default decoding or skip this part\n",
    "                    body += part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "            elif part.get_content_type() == 'text/html':\n",
    "                # Optionally handle HTML content\n",
    "                html_body = part.get_payload(decode=True)\n",
    "                charset = part.get_content_charset()\n",
    "                try:\n",
    "                    html_body = html_body.decode(charset, errors='ignore')\n",
    "                except (TypeError, UnicodeDecodeError):\n",
    "                    # Fallback to a default decoding or skip this part\n",
    "                    html_body = html_body.decode('utf-8', errors='ignore')\n",
    "                body += html_body\n",
    "    else:\n",
    "        # If the email is not multipart, get the payload directly\n",
    "        charset = msg.get_content_charset()\n",
    "        try:\n",
    "            body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "        except (TypeError, UnicodeDecodeError):\n",
    "            # Fallback to a default decoding or skip this part\n",
    "            body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "    \n",
    "    return body\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43b3a6de-d81b-463e-8c23-a307e29bdbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(html_content):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Extract and return the text without HTML tags\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b14af76-4e83-4d1b-b21d-d2f2473714a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace new lines with spaces\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Replace URLs with 'URL'\n",
    "    text = re.sub(r'http[s]?://\\S+', 'URL', text)\n",
    "    \n",
    "    # Replace numbers with 'num'\n",
    "    text = re.sub(r'\\b\\d+\\b', 'num ', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(f\"[{string.punctuation}]\", '', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a8cfab7-962d-44b6-ae66-c55d75b8bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdef8e27-d7fc-4f93-8fd1-680ef5ec297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17892\\1354375278.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(dataset)):\n",
    "    cleaned_data = clean_text(remove_html_tags(extract_body(dataset[i])))\n",
    "    X.append(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f43abcc-1848-4cdc-aecf-a7ee14b749cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3046"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ca642ee-66aa-4610-9138-dd89799f94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_X = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26b07e84-92b0-4ca2-9cd6-aa70f364cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "693e3d49-492c-47a3-88bc-4dd0e45dc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['000101c231b8fedc77400200a8c0michaels' '0002august02' '000above' ...\n",
      " '２７日' '３７日' '𤣨χaqupi']\n",
      "Dense Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Create a CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(cleaned_X)\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert to dense matrix\n",
    "dense_matrix = X.toarray()\n",
    "\n",
    "# Print results\n",
    "print(\"Vocabulary:\", feature_names)\n",
    "print(\"Dense Matrix:\")\n",
    "print(dense_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5be6994-5d09-43ff-bd45-e1ac7ae7f95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31bf19cc-4ed1-43b3-8a4b-3d5635de99de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3046, 46871)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22f97810-4a21-4bf4-b2e3-7dd377bd8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(dense_matrix, target, test_size = 0.2, stratify=target, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2b2f5b1-8ae5-4fb6-a0ed-5b45c3bfe1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "#sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "523172ea-f69d-45aa-9207-1c19708c6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "scores = cross_val_score(sgd, X_train, y_train, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "984dc052-0d65-4929-b4b6-d09dd36b8e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94581281, 0.95566502, 0.96182266])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "823ca936-e7b9-41ca-a151-c960f4bc2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44aca5bc-898e-47f1-897e-e28e94b745ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "scores_rnd = cross_val_score(rnd, X_train, y_train, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d249ff48-b87f-4e9a-b56d-8be4ea0846ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96674877, 0.96305419, 0.96674877])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41dc6aa2-00dd-4b42-8b79-fac5c447c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21d98bfc-99f8-4a5d-a6d2-8d2dde1185aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "E:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "E:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m      3\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m scores_adb \u001b[38;5;241m=\u001b[39m cross_val_score(adb, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mskf)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    732\u001b[0m )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    432\u001b[0m         clone(estimator),\n\u001b[0;32m    433\u001b[0m         X,\n\u001b[0;32m    434\u001b[0m         y,\n\u001b[0;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    446\u001b[0m     )\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    448\u001b[0m )\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[0;32m    170\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    171\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:586\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:597\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    595\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 597\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    599\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1010\u001b[0m         X,\n\u001b[0;32m   1011\u001b[0m         y,\n\u001b[0;32m   1012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1013\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mE:\\conda\\envs\\Shakshor\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "scores_adb = cross_val_score(adb, X_train, y_train, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85042c22-a7ca-47de-b0dd-dbe1e9b9dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_adb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
